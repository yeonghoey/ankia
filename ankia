#!/usr/bin/env python
# -*- coding: utf-8 -*-
from datetime import datetime
import os
import sys
import tempfile

import click
from pydub import AudioSegment
import pyperclip
import speech_recognition as sr
import urwid
import vlc


PALETTE = [
    ('normal', 'black', 'light gray'),
    ('complete', 'black', 'dark red'),
]


class TimeSlider(urwid.ProgressBar):

    def get_text(self):
        return format_dt(self.current)


@click.command()
@click.option('--anki-media', envvar='ANKI_MEDIA')
@click.argument('filepath')
def main(anki_media, filepath):
    instance = vlc.Instance()
    main_player = instance.media_player_new(filepath)
    chop_player = instance.media_player_new()

    audio = AudioSegment.from_file(filepath)
    marks = [0, 0]

    main_display = urwid.Text(filepath)
    divider1 = urwid.Divider()
    time_slider = TimeSlider('normal', 'complete', current=0, done=len(audio))
    divider2 = urwid.Divider()
    mark_display = urwid.Text('')
    divider3 = urwid.Divider()
    chop_display = urwid.Text('')

    pile = urwid.Pile([
        main_display,
        divider1,
        time_slider,
        divider2,
        mark_display,
        divider3,
        chop_display
    ])

    filler = urwid.Filler(urwid.Padding(pile, width=76, left=4), 'top', top=2)

    ctx = {
        'main_player': main_player,
        'chop_player': chop_player,

        'anki_media': anki_media,
        'audio':audio,
        'marks': marks,

        'main_display': main_display,
        'time_slider': time_slider,
        'mark_display': mark_display,
        'chop_display': chop_display,

        # can be set after input_handler
        'loop': None,
        'last_chop': '',
    }

    handler = input_handler(ctx)
    loop = urwid.MainLoop(filler, PALETTE, unhandled_input=handler)
    ctx['loop'] = loop
    main_player.play()

    main_player.get_instance().log_unset()
    loop.set_alarm_in(0.5, tick, ctx)
    loop.run()


def tick(loop, ctx):
    marks = ctx['marks']
    main_player = ctx['main_player']
    time_slider = ctx['time_slider']
    mark_display = ctx['mark_display']

    # Update slider
    t = max(main_player.get_time(), 0)
    time_slider.current = t
    mark_display.set_text('%s - %s' % tuple(format_dt(x) for x in marks))

    # To suppress errors generated by VLC
    loop.screen.clear()

    # Reschedule
    loop.set_alarm_in(0.333, tick, ctx)


def input_handler(ctx):
    main_player = ctx['main_player']
    chop_player = ctx['chop_player']

    anki_media = ctx['anki_media']

    audio = ctx['audio']
    marks = ctx['marks']

    time_slider = ctx['time_slider']
    chop_display = ctx['chop_display']

    def toggle():
        if main_player.is_playing():
            pause(main_player)
        else:
            if chop_player.is_playing():
                chop_player.stop()
            play(main_player)

    def seek(s):
        t = offset(main_player.get_time(), (s * 1000))
        main_player.set_time(t)

    def offset(t, os):
        return min(max(t + os, 0), len(audio))

    def mark_left():
        marks[0] = (main_player.get_time())

    def mark_right():
        marks[1] = (main_player.get_time())

    def chop():
        l, r = marks
        if l >= r:
            return
        pause(main_player)
        audio_slice = audio[l:r]
        now = datetime.now().strftime('%Y%m%d-%H%M%S')
        filename = now + '.mp3'
        filepath = os.path.join(anki_media, filename)
        audio_slice.export(filepath, format='mp3')
        ctx['last_chop'] = filepath
        chop_display.set_text('chopped: %s' % filename)
        chop_player.set_mrl(filepath)
        chop_player.play()


    def dump():
        loop = ctx['loop']
        last_chop = ctx['last_chop']

        if not last_chop:
            return

        filename = os.path.relpath(last_chop, anki_media)
        sound_str = '[sound:%s]' % filename

        chop_display.set_text(sound_str)
        loop.draw_screen()

        transcript = recognize(last_chop)
        text = '%s\n%s' % (sound_str, transcript)
        pyperclip.copy(text)
        chop_display.set_text(text)

    def handle(key):
        if key in ('q', 'Q'):
            raise urwid.ExitMainLoop()
        if key is ' ':
            toggle()
        if key is 'j':
            seek(-2)
        if key is 'J':
            seek(-10)
        if key is 'k':
            mark_left()
        if key is 'K':
            mark_right()
            chop()
        if key is 'l':
            seek(2)
        if key is 'L':
            seek(10)
        if key is 'a':
            l = marks[0]
            marks[0] = (offset(l, -100))
        if key is 's':
            l = marks[0]
            marks[0] = (offset(l, 100))
        if key is 'z':
            r = marks[1]
            marks[1] = (offset(r, -100))
        if key is 'x':
            r = marks[1]
            marks[1] = (offset(r, 100))
        if key is 'c':
            chop()
        if key is 'd':
            dump()

    return handle


def recognize(filepath):
    mp3 = AudioSegment.from_mp3(filepath)
    _, wav_filepath = tempfile.mkstemp()
    mp3.export(wav_filepath, format='wav')
    r = sr.Recognizer()
    with sr.AudioFile(wav_filepath) as source:
        audio = r.record(source)
        try:
            return r.recognize_google_cloud(audio)
        except (sr.RequestError, sr.UnknownValueError):
            return ''


def format_dt(ms1):
    s1, ms = divmod(ms1, 1000)
    m1, s = divmod(s1, 60)
    h, m = divmod(m1, 60)
    return '%d:%02d:%02d.%d' % (h, m, s, ms // 100)


def play(player):
    player.set_pause(0)


def pause(player):
    player.set_pause(1)


if __name__ == "__main__":
    main()
